---
title: "STAT 653 Final"
author: ' Min Tamang, ug5773'
date: "05/06/2020"
output:
  pdf_document: default
  word_document: default
  html_notebook: default
---



## Part 1


**1. What is a tokenizer? (Note: The unest_tokens() function in the tidytext R package uses the tokenizer R package.)**

Tokenizer is a function or tool that uses regular expressions to split given string into tokens. A tokenizer receives a stream of characters, breaks it up into individual tokens (usually individual words), and outputs a stream of tokens. For example unnest_tokens() function uses the tokenizers package to separate each line of text in the original data frame into token. 

**2. What is the formula for calculating the TF-IDF? Explain the two part of the calculation. What is the advantage of using the TF-IDF over just using word counts?**


The formula for TF-IDF = TFxIDF 
where first part of the calculation is normalized term frequency. It measures how frequently a word occurs in a document. It can be defined as, 
$$\text{TF} = (\frac{\text{number of times term appears in a document}}{\text{Total number of terms in the document}})$$
whereas, second part of the calculation is inverse document frequency which decreases the weight for commonly used words and increases the weight for words that are not used very much in a collection of documents. It can be defined as,
$$\text{IDF} = \ln(\frac{n_{\text{documents}}}{n_{\text{document containing term}}})$$

tf-idf measures how important a word is to a document in a collection (or corpus) of documents, for example, to one book in a collection of books whereas just using word counts we may  not be able to measure importance of words in a corpus. 



**3.Read the excellent blog post from the Demonstration of tidytext using Darwinâ€™s "On the Origin of Species". Run all of the code in this blog post in your R Notebook and explain each step presented. Discuss any differences you see in the sentiment analysis performed using different lexicons.**


```{r}
#load libraries
library(tidytext)
library(dplyr)
library(readr)
library(ggplot2)
library(tidyr)
library(stringr)
library(purrr)
```

**Get the book**
```{r}
# load the book from the gutengbergr library
library(gutenbergr)
res <- gutenberg_works(str_detect(title, regex("on the origin of species", ignore_case = TRUE)))
res %>% select(title)
```


```{r}
# see the books under the same title 
res %>% select(gutenberg_id)
```


```{r}
# download the 1st edition
ofs_full <- gutenberg_download(1228)
ofs_full
```




**Make it tidy**

**Remove the preface**
```{r}
# row number where the word introduction occurs
grep("INTRODUCTION\\.", ofs_full$text)
# remove the white space to get the actual start of the book
grep("^INTRODUCTION\\.", ofs_full$text)
```

**Table of contents**
```{r}
# find index line 
grep("^INDEX\\.", ofs_full$text)
# extract the boundarires of the actual text in the book
ofs <- ofs_full %>% slice(grep("^INTRODUCTION\\.",text):(grep("^INDEX\\.", text))-1)
ofs
```


```{r}
# each chapter
grep("^[0-9]+\\.", ofs$text, value=TRUE)
```

```{r}
#blank lines, true for not blank
head(nzchar(ofs$text))
```



**Putting it all together**
```{r}
# create new columns to keep track of line number and chapters
ofs <- ofs_full %>%
  slice(grep("^INTRODUCTION\\.", text):(grep("^INDEX\\.", text))-1) %>%
  filter(nzchar(text)) %>%
  mutate(linenumber = row_number(),
         chapter = cumsum(grepl("^[0-9]+\\.", text)))
```


**Using tidytext to make it tidy**
```{r}
# tokenize the texts
ofs_tidy <- ofs %>% unnest_tokens(word, text)
# remove stop words
ofs_tidy <- ofs_tidy %>% anti_join(stop_words)
```



**What are the most common words in the Origin of Species**

```{r}
  ofs_tidy %>%
  count(word, sort=TRUE) %>%
  top_n(15) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(x = word, y = n)) +
  geom_col() +
  xlab(NULL) +
  coord_flip()
```



**Relationships between words**
```{r}
# bigram: tokenize text into pairs of two consecutive words and remove stop words
ofs_bigram <- ofs %>%
  unnest_tokens(bigram, text, token="ngrams", n=2)

ofs_separated <- ofs_bigram %>%
  separate(bigram, c("word1", "word2"), sep =" ")

ofs_filtered <- ofs_separated %>%
  filter(!word1 %in% stop_words$word,
         !word2 %in% stop_words$word) %>%
  unite(bigram, word1, word2, sep = " ")
```


```{r}
# remove NA NA pair
ofs_filtered <- ofs_filtered %>% filter(bigram != "NA NA")
```

```{r}
#count and plot top 15 pairs
ofs_filtered %>%
  count(bigram, sort=TRUE) %>%
  top_n(15) %>%
  mutate(bigram = reorder(bigram, n)) %>%
  ggplot(aes(x=bigram, y=n)) +
  geom_col() +
  coord_flip() 
```


**Sentiment analysis**

```{r}
# join with afinn lexicon
afinn <- ofs_tidy %>%
  inner_join(get_sentiments("afinn")) %>%
  group_by(chapter, index = linenumber %/% 80) %>%
  summarize(sentiment = sum(value)) %>%
  mutate(method = "AFINN")

# join with bing and nrc lexicons
bing_and_nrc <- bind_rows(ofs_tidy %>%
                            inner_join(get_sentiments("bing")) %>%
                            mutate(method = "Bing et al."),
                          ofs_tidy %>%
                            inner_join(get_sentiments("nrc") %>%
                                         filter(sentiment %in% c("positive", "negative"))) %>% mutate(method = "NRC")) %>%
  count(method, index = linenumber %/% 80,  chapter, sentiment) %>%
  spread(sentiment, n, fill = 0) %>%
  mutate(sentiment = positive - negative)

#plot to see sentiment trends
  bind_rows(afinn, bing_and_nrc) %>%
  ggplot(aes(index, sentiment, fill = as.factor(chapter))) +
  geom_col() +
  facet_wrap(~ method, ncol = 1,, scales = "free_y") +
  scale_fill_discrete(name="", 
                      labels=c("Introduction",paste("Chapter", 1:14)))
```

Bing seems to have higher negativity scores which makes sense given bing scores either as negative or positive whereas NRC seems to have much higher positivity scores. Negative scores are higher in chapter 3 in affin and bing which makes sense given chapter 3 is about struggle for existence. Based on affin, overall sentiments seem to be distributed evenly throughout the book. 




**Features of the final chapter**


```{r}
# log odd ratio of the word that occur at least 10 times in the final
# chapter to the rest of the book
word_ratios <- ofs_tidy %>%
    group_by(conclusion = chapter == 14) %>%
    count(word, conclusion) %>%
    filter(n >= 10) %>%
    ungroup() %>%
    spread(conclusion, n, fill = 0) %>%
    rename(conclusion = `TRUE`, restofbook = `FALSE`) %>%
    mutate_if(is.numeric, funs((. + 1)/sum(. +1))) %>%
    mutate(logratio = log(conclusion/restofbook)) %>%
    arrange(desc(logratio))

# plot top 10 most distinctive words from the entire book compared to the final chapter
word_ratios %>%
    mutate(abslogratio = abs(logratio)) %>%
    group_by(logratio < 0) %>%
    top_n(10, abslogratio) %>%
    ungroup() %>%
    mutate(word = reorder(word, logratio)) %>%
    ggplot(aes(word, logratio, fill = logratio < 0)) +
    geom_col() +
    coord_flip() +
    ylab("log odds (Chapter 14/Rest of Book)") +
    scale_fill_discrete(name = "", labels = c("Chapter 14", "Rest of Book")) 
```


```{r}
# use of word "evolved"
ofs_tidy %>% filter(str_detect(word, "^evol"))
# used only once in the last line 
max(ofs_tidy$linenumber)
```


**4.Read the excellent blog post by Julia Silge GENDER ROLES WITH TEXT MINING AND N-GRAMS. Run all of the code in this blog post in your R Notebook and explain each step presented. What are the differences discovered in gender roles between the authors? Would this analysis be possible without using bigrams? Another blog post by Julia that is interesting She Giggles, He Gallops.**


**Jane Austen and n-grams**
```{r}
library(tidyverse)
library(tidytext)
library(janeaustenr)
# identify bigrams from Jane Austen books
austen_bigrams <- austen_books() %>%
  unnest_tokens(bigram, text, token = "ngrams", n = 2)
austen_bigrams
```


```{r}
# bigrams with "he" and "she"
pronouns <-c("he","she")
bigram_counts <- austen_bigrams %>%
    count(bigram, sort = TRUE) %>%
    separate(bigram, c("word1", "word2"), sep = " ") %>%
    filter(word1 %in% pronouns) %>%
    count(word1, word2, wt = n, sort = TRUE) %>%
    rename(total = n)

bigram_counts
```


```{r}
# calculate log odds ratio
word_ratios <- bigram_counts %>%
    group_by(word2) %>%
    filter(sum(total) > 10) %>%
    ungroup() %>%
    spread(word1, total, fill = 0) %>%
    mutate_if(is.numeric, funs((. + 1) / sum(. + 1))) %>%
    mutate(logratio = log2(she / he)) %>%
    arrange(-(logratio)) 
word_ratios
```

```{r}
# words with likelyhood of following "she" and "he"
word_ratios %>% arrange(abs(logratio))

```


```{r}
# words that exhibit the largest differences in appearing after "she"
# compared to "he", plot top 15 words with each pronoun
word_ratios %>%
    mutate(abslogratio = abs(logratio)) %>%
    group_by(logratio < 0) %>%
    top_n(15, abslogratio) %>%
    ungroup() %>%
    mutate(word = reorder(word2, logratio)) %>%
    ggplot(aes(word, logratio, color = logratio < 0)) +
    geom_segment(aes(x = word, xend = word,
                     y = 0, yend = logratio), 
                     size = 1.1, alpha = 0.6) +
    geom_point(size = 3.5) +
    coord_flip() +
    labs(x = NULL, 
         y = "Relative appearance after 'she' compared to 'he'",
         title = "Words paired with 'he' and 'she' in Jane Austen's novels", subtitle = "Women remember, read, and feel while men stop, take, and reply") + scale_color_discrete(name = "", labels = c("More 'she'", "More 'he'")) + scale_y_continuous(breaks = seq(-3, 3),labels = c("0.125x", "0.25x", "0.5x", "Same", "2x", "4x", "8x"))
```




**George Eliot and n-grams**
```{r}
# download George Eliot books
eliot <- gutenberg_download(c(145,550,6688),
        mirror = "http://mirrors.xmission.com/gutenberg/")
```


```{r}
# the log odds ratios for each word that comes after "he" and "she"
eliot_ratios <- eliot %>%
    unnest_tokens(bigram, text, token = "ngrams", n = 2) %>%
    count(bigram, sort = TRUE) %>%
    ungroup() %>%
    separate(bigram, c("word1", "word2"), sep = " ") %>%
    filter(word1 %in% pronouns) %>%
    count(word1, word2, wt = n, sort = TRUE) %>%
    rename(total = n) %>%
    group_by(word2) %>%
    filter(sum(total) > 10) %>%
    ungroup() %>%
    spread(word1, total, fill = 0) %>%
    mutate_if(is.numeric, funs((. + 1) / sum(. + 1))) %>%
    mutate(logratio = log2(she / he)) %>%
    arrange(desc(logratio))

# words that exhibit the largest differences in appearing after "she"
# compared to "he", plot top 15 words with each pronoun
eliot_ratios %>%
    mutate(abslogratio = abs(logratio)) %>%
    group_by(logratio < 0) %>%
    top_n(15, abslogratio) %>%
    ungroup() %>%
    mutate(word = reorder(word2, logratio)) %>%
    ggplot(aes(word, logratio, color = logratio < 0)) +
    geom_segment(aes(x = word, xend = word,
                     y = 0, yend = logratio), 
                     size = 1.1, alpha = 0.6) +
    geom_point(size = 3.5) +
    coord_flip() +
    labs(x = NULL, 
         y = "Relative appearance after 'she' compared to 'he'",
         title = "Words paired with 'he' and 'she' in George Eliot's novels", subtitle = "Women read, run, and need while men leave, mean, and tell") + scale_color_discrete(name = "", labels = c("More 'she'", "More 'he'")) + scale_y_continuous(breaks = seq(-5, 5),labels = c("0.03125x", "0.0625x", "0.125x", "0.25x", "0.5x", "Same", "2x", "4x", "8x", "16x", "32x"))
```


**Jane Eyre and n-grams**
```{r}
# download Jane Eyre novel
eyre <- gutenberg_download(1260,
       mirror = "http://mirrors.xmission.com/gutenberg/")
```

```{r}
# the log odds ratios for each word that comes after "he" and "she"
eyre_ratios <- eyre %>%
    unnest_tokens(bigram, text, token = "ngrams", n = 2) %>%
    count(bigram, sort = TRUE) %>%
    ungroup() %>%
    separate(bigram, c("word1", "word2"), sep = " ") %>%
    filter(word1 %in% pronouns) %>%
    count(word1, word2, wt = n, sort = TRUE) %>%
    rename(total = n) %>%
    group_by(word2) %>%
    filter(sum(total) > 5) %>%
    ungroup() %>%
    spread(word1, total, fill = 0) %>%
    mutate_if(is.numeric, funs((. + 1) / sum(. + 1))) %>%
    mutate(logratio = log2(she / he)) %>%
    arrange(desc(logratio))


 #words that exhibit the largest differences in appearing after "she"
# compared to "he", plot top 15 words with each pronoun
eyre_ratios %>%
    mutate(abslogratio = abs(logratio)) %>%
    group_by(logratio < 0) %>%
    top_n(15, abslogratio) %>%
    ungroup() %>%
    mutate(word = reorder(word2, logratio)) %>%
    ggplot(aes(word, logratio, color = logratio < 0)) +
    geom_segment(aes(x = word, xend = word,
                     y = 0, yend = logratio), 
                  size = 1.1, alpha = 0.6) +
    geom_point(size = 3.5) +
    coord_flip() +
    labs(x = NULL, 
         y = "Relative appearance after 'she' compared to 'he'",
         title = "Words paired with 'he' and 'she' in Jane Eyre",
         subtitle = "Women look, tell, and open while men stop, smile, and pause") + scale_color_discrete(name = "", labels = c("More 'she'", "More 'he'")) +scale_y_continuous(breaks = seq(-3, 3),labels = c("0.125x", "0.25x", "0.5x", "Same", "2x", "4x", "8x"))
```


In novels by Jane Austen and George Eliot, the verbs associated with women are more connected to the emotion or feeling whereas the verbs connected with men are more connected to action or speaking. Whereas verbs associated with women in Jane Eyre's novels are not particularly emotion-feeling oriented. The words associated with men are somewhat similar to action orientation. 

The purpose of this type of analysis is to discover relationships between words. Therefore, it is not possible without using bigrams.




